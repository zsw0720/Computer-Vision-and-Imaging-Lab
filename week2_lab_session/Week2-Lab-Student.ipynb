{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Session: Week 2 - Feature Detection and Deep Learning\n",
    "\n",
    "Welcome to the lab session! In this tutorial, we will guide you through **OpenCV** and **PyTorch**. The session includes two exercises, progressing from easy to more challenging tasks.\n",
    "\n",
    "### Session Structure:\n",
    "**Exercises**:\n",
    "   - **Level 1 (OpenCV)**: Image operation using OpenCV (easy).\n",
    "   - **Level 2 (PyTorch)**: Deep learning tasks using PyTorch (more advanced).\n",
    "\n",
    "### Instructions:\n",
    "- Follow the tutorial closely for each level, including filling the code blanks and answering questions.\n",
    "- Complete the exercises after reviewing the material.\n",
    "- Feel free to ask questions if you encounter any difficulties.\n",
    "\n",
    "### Enjoy the session and happy learning!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: OpenCV\n",
    "\n",
    "As CVer, the data we deal with are images. OpenCV is a library of programming functions mainly for real-time computer vision. It can be applied in many fields and provides rich functions for processing images and videos. Therefore, before diving into the world of computer vision, it is necessary to master some basic image processing techniques.\n",
    "\n",
    "In this section, you will write a simple OpenCV script that:\n",
    "\n",
    "1. Load the data from an image file and print the shape of the image.\n",
    "2. Resize the image.\n",
    "3. Flip the image horizontally and vertically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image and print the shape of the image\n",
    "\n",
    "# Path to the image file\n",
    "img_path = './cs_building.png'\n",
    "\n",
    "# Blank 1: Load the image using OpenCV's imread function\n",
    "# Hint: Use cv2.imread() to read the image from the file.\n",
    "img = cv2.imread(img_path) # Complete the line to load the image\n",
    "\n",
    "# Blank 2: Print the shape of the image (height, width, channels)\n",
    "# Hint: Use the .shape attribute of the image to print its dimensions.\n",
    "print(img.shape)  # Complete the line to print the shape of the image\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank 3: Resize the image using OpenCV's resize function\n",
    "# Hint: Use cv2.resize() to resize the image. The function takes the image and the desired dimensions (width, height) as inputs.\n",
    "img_resized = cv2.resize(img,(img.shape[1]//2,img.shape[0]//2)) # Complete the line to resize the image\n",
    "#将图像缩放为原来的一半大小  cv2.resize()\n",
    "\n",
    "# Display the resized image using matplotlib\n",
    "plt.imshow(img_resized)\n",
    "plt.title('Resized Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the image horizontally and vertically using NumPy\n",
    "\n",
    "# Blank 4: Flip the image horizontally\n",
    "# Hint: Use NumPy slicing to flip the image along the horizontal axis (flip across width).\n",
    "horizontally_flipped_np = np.fliplr(img) # 水平翻转（沿着宽度轴反转） numpy.fliplr()左右变化 # Complete the line to flip the image horizontally\n",
    "\n",
    "# Blank 5:  Flip the image vertically\n",
    "# Hint: Use NumPy slicing to flip the image along the vertical axis (flip across height).\n",
    "vertically_flipped_np = np.flipud(img) # Complete the line to flip the image vertically\n",
    "\n",
    "# Display the horizontally and vertically flipped images\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(horizontally_flipped_np)\n",
    "plt.title(\"Horizontally Flipped\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(vertically_flipped_np)\n",
    "plt.title(\"Vertically Flipped\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Besides using NumPy, OpenCV also allows you to flip images easily.\n",
    "\n",
    "# Flip the image horizontally and vertically using OpenCV\n",
    "\n",
    "# Blank 6: Flip the image horizontally\n",
    "# Hint: Use cv2.flip() with the specific flip code to flip the image horizontally.\n",
    "horizontally_flipped = cv2.flip(img,1) # Complete this line\n",
    "\n",
    "# Blank 7: Flip the image vertically\n",
    "# Hint: Use cv2.flip() with the specific flip code to flip the image vertically.\n",
    "vertically_flipped = cv2.flip(img,0) # Complete this line\n",
    "\n",
    "# Display the horizontally and vertically flipped images\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(horizontally_flipped)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(vertically_flipped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: What is the difference between the picture displayed by `plt.show` and the original picture?\n",
    "#answer:The default is BGR, which needs to be converted to RGB to be displayed correctly in matplotlib(默认是 BGR，需要转换为 RGB 才能在 matplotlib 正确显示)\n",
    "Hint 1 : Image is usually composed of three channels: R (red), G (green), and B (blue). These three channels represent the color information of the image, and the value range of each channel is usually 0 to 255, which is used to represent the color intensity from the darkest to the brightest.\n",
    "\n",
    "Hint 2 : What is the order of channels read by cv2.imread?\n",
    "answer:The OpenCV assumes images are in BGR channel order.OpenCV imread, imwrite and imshow all work with the BGR order, so the image won't change if we use cv2. imshow to show the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: How to use `cv2` and `plt.imshow` to correctly load and display an image?\n",
    "\n",
    "In the previous example, we used `img = cv2.imread(img_path)` to load the image. However, you may notice that the colors of the image appear incorrect, such as the building displaying unusual colors. Try to explore the reason behind it and give the correct way using `cv2` and `plt.imshow` to display the image. After this, please fill the following blank.\n",
    "\n",
    "answer:OpenCV (cv2) uses BGR formatting (Blue, Green, Red) by default when reading images.\n",
    "However, matplotlib.pyplot.imshow() displays images using RGB formatting (Red, Green, Blue).\n",
    "This can lead to unusual color effects, such as the sky turning orange and buildings appearing strangely colored.After reading an image with cv2.imread() , use cv2.cvtColor() to convert the BGR format to RGB before displaying it.\n",
    "{OpenCV (cv2) 在读取图像时，默认是 BGR 顺序（Blue, Green, Red），\n",
    "而 matplotlib.pyplot.imshow() 显示图像时，使用的是 RGB 顺序（Red, Green, Blue）。\n",
    "这就导致看到颜色异常，比如：天空变成橙色,建筑出现奇怪的颜色\n",
    "在用 cv2.imread() 读取图像后，要在显示前使用 cv2.cvtColor() 把 BGR 转换成 RGB。}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank 8: find the correct way to read an image\n",
    "img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "# the numpy verson of correctly reading an image\n",
    "B, G, R  = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "img_rgb_numpy = np.dstack((R, G, B))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_rgb)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_rgb_numpy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: PyTorch - Background Introduction\n",
    "\n",
    "PyTorch is a powerful deep learning framework that has gained significant popularity due to its dynamic computation graph and ease of use. Learning PyTorch is essential for anyone interested in deep learning because it is widely used in both academia and industry for developing state-of-the-art models. From basic neural networks to advanced architectures like convolutional neural networks (CNNs卷积神经网络) and recurrent neural networks (RNNs循环神经网络), PyTorch provides all the necessary tools to design, train, and deploy machine learning models efficiently.\n",
    "\n",
    "### Why Learn PyTorch?\n",
    "\n",
    "1. **Flexibility**: PyTorch's dynamic computation graph allows you to experiment with different network architectures and quickly iterate(迭代) on models.\n",
    "2. **Community and Ecosystem**: PyTorch has a strong community and a rich ecosystem of libraries and tools, which makes it easier to find support, resources, and pre-trained models.\n",
    "3. **Industry Relevance**: Many leading tech companies and research labs use PyTorch, making it a valuable skill for a career in machine learning and AI.\n",
    "4. **Ease of Use**: PyTorch’s design is intuitive(直观的), especially for those familiar with Python, and its integration with other Python libraries allows for seamless(无缝的) workflow management.\n",
    "\n",
    "In this section, you will write a simple PyTorch script that defines a basic neural network, trains it on a dataset, and evaluates its performance. This exercise will help you get hands-on experience with PyTorch's core concepts, such as tensors（向量), autograd(自动微分引擎), and the training loop（训练循环）.\n",
    "\n",
    "You will:\n",
    "\n",
    "#### 2.1 Tensor\n",
    "\n",
    "- Learn the basics of tensors.\n",
    "\n",
    "#### 2.2 Data Loading, Training, Optimization（最优化）, and Testing\n",
    "###     数据装载->训练->优化->测试\n",
    "\n",
    "- Define a neural network using `torch.nn`.\n",
    "- Train the network using a dataset like MNIST or CIFAR-10.\n",
    "- Implement the training loop, including loss calculation and backpropagation（反向传播）.\n",
    "- Evaluate the model’s performance on a validation set.\n",
    "\n",
    "Let's get started with the exercise and see how PyTorch can be used to build and train a neural network from scratch!\n",
    "\n",
    "### **Exercise: You will be asked to write a Simple Training Code following tutorials**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 Tensors\n",
    "\n",
    "Tensors are a specialized data structure that are very similar to arrays\n",
    "and matrices. In PyTorch, we use tensors to encode the inputs and\n",
    "outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "Tensors are similar to NumPy’s ndarrays, except that tensors can run on\n",
    "GPUs or other specialized hardware to accelerate computing. If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along in this quick API walkthrough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Initialization\n",
    "\n",
    "Tensors can be initialized in various ways. Take a look at the following examples:\n",
    "\n",
    "**Directly from data**\n",
    "\n",
    "Tensors can be created directly from data. The data type is automatically inferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From a NumPy array**\n",
    "\n",
    "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From another tensor:**\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With random or constant values:**\n",
    "\n",
    "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Attributes\n",
    "\n",
    "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "\n",
    "Over 100 tensor operations, including transposing, indexing, slicing,\n",
    "mathematical operations, linear algebra, random sampling, and more are\n",
    "comprehensively described\n",
    "[here](https://pytorch.org/docs/stable/torch.html)_.\n",
    "\n",
    "Each of them can be run on the GPU (at typically higher speeds than on a\n",
    "CPU). If you’re using Colab, allocate a GPU by going to Edit > Notebook\n",
    "Settings.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some of the operations from the list.\n",
    "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard numpy-like indexing and slicing:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
    "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_,\n",
    "another tensor joining op that is subtly different from ``torch.cat``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiplying tensors**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computes the matrix multiplication between two tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
    "locations, and changing one will change\tthe other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor to NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy array to Tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Data Loading, Training, Optimization, and Testing\n",
    "\n",
    "## 2.2.1 Load Data\n",
    "\n",
    "\n",
    "Generally, when you have to deal with image, text, audio or video data,\n",
    "you can use standard python packages that load data into a numpy array.\n",
    "Then you can convert this array into a ``torch.*Tensor``.\n",
    "\n",
    "-  For images, packages such as Pillow, OpenCV are useful\n",
    "-  For audio, packages such as scipy and librosa\n",
    "-  For text, either raw Python or Cython based loading, or NLTK and\n",
    "   SpaCy are useful\n",
    "\n",
    "Specifically for vision, we have created a package called\n",
    "``torchvision``, that has data loaders for common datasets such as\n",
    "ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
    "[``torchvision.datasets``](https://pytorch.org/vision/stable/datasets.html) and ``torch.utils.data.DataLoader``.\n",
    "\n",
    "This provides a huge convenience and avoids writing boilerplate code.\n",
    "\n",
    "Here we will use the CIFAR10 dataset.\n",
    "It has 10 classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "\n",
    "### 1. Load and normalize CIFAR10\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
###transforms.ToTensor()：把 PIL 图片转换成 PyTorch Tensor。
Normalize((0.5,...), (0.5,...))：将数据归一化到 [-1, 1]。
下载并加载 CIFAR-10 数据集，包含 10 个类别，每张图片是 32x32 的彩色图像。
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Let us show some of the training images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.Define a Convolutional Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)  \n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 64)  \n",
    "        self.fc2 = nn.Linear(64, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a loss function and optimizer\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the network. \n",
    "\n",
    "**Here comes an exercise: Implement a Basic Training Loop in PyTorch.**\n",
    "\n",
    "This is when things start to get interesting.\n",
    "\n",
    "Based on the steps you've completed so far, your task is to write a training loop that trains the neural network model you've defined using the dataset you've already loaded.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- Training Loop:\n",
    "\n",
    "Implement a training loop that runs for 1 epochs.\n",
    "For each mini-batch of data, perform the following steps:\n",
    "1. Forward Pass: Pass the inputs through the network to get the outputs.\n",
    "2. Loss Calculation: Compute the loss using the predefined loss function (criterion).\n",
    "3. Zero Gradients: Before backpropagation, ensure the gradients are zeroed using optimizer.zero_grad().\n",
    "4. Backward Pass: Perform backpropagation by calling loss.backward() to compute the gradients.\n",
    "5. Parameter Update: Update the model’s parameters using the optimizer (optimizer.step()).\n",
    "\n",
    "- Output the Loss:\n",
    "\n",
    "Track the running loss during training and print the average loss for every 2000 mini-batches to monitor the training process.\n",
    "Completion Message:\n",
    "\n",
    "After completing the 1 epochs, print a message indicating that the training is finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Please write the code related to zero gradienct here.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # Please write the forward pass code here\n",
    "        outputs = net(inputs)\n",
    "        # Please write the loss calculation code here.\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Remember that we have chosen \"criterion = nn.CrossEntropyLoss()\" in the last cell\n",
    "\n",
    "        \n",
    "        # Please write the Backward Pass code here.\n",
    "        loss.backward()\n",
    "        # Please write the Parameter Update code here.\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 1:    # print every 1000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar10_model.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test the network on the test data\n",
    "\n",
    "We have trained the network for 3 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Now, let's load back in our saved model (note: saving and re-loading the model wasn't necessary here, we only did it to illustrate how to do so):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are.\n",
    "\n",
    "The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about your result look like?\n",
    "### concluding car plane truck plane\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is your network performance look like? \n",
    "Did your network learn something?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    " - [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNNVisualisation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
